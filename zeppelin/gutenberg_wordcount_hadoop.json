{"paragraphs":[{"text":"%sh\n# Download the book from Project Gutenberg\nwget -O pride_and_prejudice.txt https://www.gutenberg.org/files/1342/1342-0.txt\n\n#hdfs dfs -rm pride_and_prejudice.txt\n\n# Upload the book to HDFS\nhdfs dfs -put pride_and_prejudice.txt hdfs://namenode:9000/\n\n# Display the first few lines of the file in HDFS\n#hdfs dfs -head /pride_and_prejudice.txt","user":"anonymous","dateUpdated":"2024-10-15T17:54:17+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"--2024-10-15 17:54:17--  https://www.gutenberg.org/files/1342/1342-0.txt\nResolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\nConnecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 752583 (735K) [text/plain]\nSaving to: ‘pride_and_prejudice.txt’\n\n     0K .......... .......... .......... .......... ..........  6%  213K 3s\n    50K .......... .......... .......... .......... .......... 13%  426K 2s\n   100K .......... .......... .......... .......... .......... 20% 73.6M 1s\n   150K .......... .......... .......... .......... .......... 27%  430K 1s\n   200K .......... .......... .......... .......... .......... 34% 78.1M 1s\n   250K .......... .......... .......... .......... .......... 40%  119M 1s\n   300K .......... .......... .......... .......... .......... 47% 90.7M 1s\n   350K .......... .......... .......... .......... .......... 54%  432K 0s\n   400K .......... .......... .......... .......... .......... 61% 86.6M 0s\n   450K .......... .......... .......... .......... .......... 68% 95.8M 0s\n   500K .......... .......... .......... .......... .......... 74% 75.9M 0s\n   550K .......... .......... .......... .......... .......... 81%  105M 0s\n   600K .......... .......... .......... .......... .......... 88%  121M 0s\n   650K .......... .......... .......... .......... .......... 95% 96.6M 0s\n   700K .......... .......... .......... ....                 100%  113M=0.6s\n\n2024-10-15 17:54:18 (1.22 MB/s) - ‘pride_and_prejudice.txt’ saved [752583/752583]\n\nput: `hdfs://namenode:9000/pride_and_prejudice.txt': File exists\n"},{"type":"TEXT","data":"ExitValue: 1"}]},"apps":[],"jobName":"paragraph_1729010826098_449671571","id":"paragraph_1683720000000_1234567890","dateCreated":"2024-10-15T16:47:06+0000","dateStarted":"2024-10-15T17:54:17+0000","dateFinished":"2024-10-15T17:54:19+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:13340"},{"text":"%sh\nls -alt","user":"anonymous","dateUpdated":"2024-10-15T17:52:57+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"total 28808\ndrwxr-xr-x  1  501 root     4096 Oct 15 17:52 .\ndrwxr-xr-x  2 root root     4096 Oct 15 17:52 run\ndrwxr-xr-x  1  501 root     4096 Oct 15 17:50 conf\ndrwxr-xr-x  3 root root     4096 Oct 15 17:50 local-repo\ndrwxr-xr-x  3 root root     4096 Oct 15 17:50 webapps\n-rw-r--r--  1 root root   752583 Jun 17 19:41 pride_and_prejudice.txt\ndrwxr-xr-x  1 root root     4096 Dec 29  2017 ..\ndrwxr-xr-x  2  501 root     4096 Dec 29  2017 bin\ndrwxr-xr-x 23  501 root     4096 Dec 29  2017 interpreter\ndrwxr-xr-x  4  501 root    12288 Dec 29  2017 lib\ndrwxr-xr-x  2  501 root     4096 Dec 29  2017 licenses\ndrwxr-xr-x  8  501 root     4096 Dec 29  2017 notebook\n-rw-r--r--  1  501 root    59610 Jun  9  2017 LICENSE\n-rw-r--r--  1  501 root     5620 Jun  9  2017 NOTICE\n-rw-r--r--  1  501 root 28609568 Jun  9  2017 zeppelin-web-0.7.2.war\n-rw-r--r--  1  501 root     1324 Jun  9  2017 README.md\n"}]},"apps":[],"jobName":"paragraph_1729012794136_948693063","id":"20241015-171954_1657954586","dateCreated":"2024-10-15T17:19:54+0000","dateStarted":"2024-10-15T17:52:57+0000","dateFinished":"2024-10-15T17:52:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13341"},{"text":"%sh\nhdfs dfs -ls hdfs://namenode:9000/","user":"anonymous","dateUpdated":"2024-10-15T17:54:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Found 3 items\ndrwxr-xr-x   - root supergroup          0 2024-10-15 17:30 hdfs://namenode:9000/fe\n-rw-r--r--   3 root supergroup     752583 2024-10-15 17:52 hdfs://namenode:9000/pride_and_prejudice.txt\ndrwxr-xr-x   - root supergroup          0 2024-10-15 15:19 hdfs://namenode:9000/rmstate\n"}]},"apps":[],"jobName":"paragraph_1729010894850_-264548270","id":"20241015-164814_1191680467","dateCreated":"2024-10-15T16:48:14+0000","dateStarted":"2024-10-15T17:54:04+0000","dateFinished":"2024-10-15T17:54:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13342"},{"text":"%sh\n# Create a MapReduce job for word count\ncat << EOF > WordCount.java\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\npublic class WordCount {\n\n  public static class TokenizerMapper\n       extends Mapper<Object, Text, Text, IntWritable>{\n\n    private final static IntWritable one = new IntWritable(1);\n    private Text word = new Text();\n\n    public void map(Object key, Text value, Context context\n                    ) throws IOException, InterruptedException {\n      StringTokenizer itr = new StringTokenizer(value.toString());\n      while (itr.hasMoreTokens()) {\n        word.set(itr.nextToken().replaceAll(\"[^a-zA-Z]\", \"\").toLowerCase());\n        if (word.getLength() > 0) {\n          context.write(word, one);\n        }\n      }\n    }\n  }\n\n  public static class IntSumReducer\n       extends Reducer<Text,IntWritable,Text,IntWritable> {\n    private IntWritable result = new IntWritable();\n\n    public void reduce(Text key, Iterable<IntWritable> values,\n                       Context context\n                       ) throws IOException, InterruptedException {\n      int sum = 0;\n      for (IntWritable val : values) {\n        sum += val.get();\n      }\n      result.set(sum);\n      context.write(key, result);\n    }\n  }\n\n  public static void main(String[] args) throws Exception {\n    Configuration conf = new Configuration();\n    Job job = Job.getInstance(conf, \"word count\");\n    job.setJarByClass(WordCount.class);\n    job.setMapperClass(TokenizerMapper.class);\n    job.setCombinerClass(IntSumReducer.class);\n    job.setReducerClass(IntSumReducer.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(IntWritable.class);\n    FileInputFormat.addInputPath(job, new Path(args[0]));\n    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n    System.exit(job.waitForCompletion(true) ? 0 : 1);\n  }\n}\nEOF\n\n# Compile the Java code\njavac -classpath $(hadoop classpath) WordCount.java\n\n# Create a JAR file\njar cf wc.jar WordCount*.class\n\n# Run the MapReduce job\nhadoop jar wc.jar WordCount hdfs://namenode:9000/pride_and_prejudice.txt hdfs://namenode:9000/output\n\n# Display the results (top 20 words)\nhdfs dfs -cat hdfs://namenode:9000/output/part-r-00000 | sort -k2 -nr | head -n 20","user":"anonymous","dateUpdated":"2024-10-15T17:56:51+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"24/10/15 17:56:53 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n24/10/15 17:56:53 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\nException in thread \"main\" org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://namenode:9000/output already exists\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:268)\n\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:141)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1807)\n\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)\n\tat WordCount.main(WordCount.java:61)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.util.RunJar.run(RunJar.java:234)\n\tat org.apache.hadoop.util.RunJar.main(RunJar.java:148)\nthe\t4655\nto\t4291\nof\t3836\nand\t3713\nher\t2276\ni\t2102\na\t2021\nin\t1977\nwas\t1874\nshe\t1744\nthat\t1623\nit\t1574\nnot\t1497\nyou\t1362\nhe\t1356\nhis\t1302\nbe\t1260\nas\t1229\nhad\t1185\nwith\t1098\n"}]},"apps":[],"jobName":"paragraph_1729010826100_447363078","id":"paragraph_1683720000001_1234567891","dateCreated":"2024-10-15T16:47:06+0000","dateStarted":"2024-10-15T17:56:51+0000","dateFinished":"2024-10-15T17:56:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:13343"},{"text":"%sh\n","user":"anonymous","dateUpdated":"2024-10-15T16:52:28+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1729011148320_-580074661","id":"20241015-165228_1571699226","dateCreated":"2024-10-15T16:52:28+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:13344"}],"name":"Gutenberg Word Count (Hadoop)","id":"2K9Y1PCEX","angularObjects":{"2KAU4Z9SW:shared_process":[],"2KD732CP6:shared_process":[],"2K9XQK6WF:shared_process":[],"2KAVFE3G8:shared_process":[],"2K9Z3K228:shared_process":[],"2KAYVCY5M:shared_process":[],"2KCD3EYTJ:shared_process":[],"2KCXT5CXZ:shared_process":[],"2KCXJG7NR:shared_process":[],"2KBXGYGAE:shared_process":[],"2KCW96ASW:shared_process":[],"2KASQQMKV:shared_process":[],"2KCF4A7V7:shared_process":[],"2KBZM3EKR:shared_process":[],"2KAY229DE:shared_process":[],"2KAKKP6C2:shared_process":[],"2KD35Z8H1:shared_process":[],"2KC34ZKSX:shared_process":[],"2KB9K6UVX:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}